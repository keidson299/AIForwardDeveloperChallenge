# Reflections on the Challenge

Overall, I really enjoyed this developer challenge. It was really nice to be pushed to use not just AI models in software development, but as the thing being developed and tested. While I had some past experience with Model Context Protocol, server design and implementation, and using AI models, this challenge pushed it to a whole new level. It required me to rethink how I approached the development process, how I thought about testing and validating my implementation, and how I could best document my processes. I did see a great amount of benefit from using AI models, and specifically Claude Sonnet, throughout this project. But, using Claude as extensively as I did, I became much more familiar with the issues that still exist when using AI models to develop software products. So, let's go through what went well, and what went not so well.

## The Benefits I Saw
First and foremost, the greatest benefit was the speed of writing code. While I am a decent typist, I am not the fastest and having Claude whip up a quick test case, or add additional features to a file is a godsend. It becomes espcially beneficial when you utilize the context feature these models provide to help focus the output to exactly what you need. There were many instances when I could simply insert a file or two as the context, ask a question or ask for an implementation, and I would get a (mostly) coherent output that I could slot right into my code.

The second benefit I saw was regarding research. I am pretty good at using google and other search engines to find information about the topics I am interested in, however Claude provided an entirely different way of searching that was great to use. Normally I would search through websites which generally meant hoping the short snippit google provides will lead to a larger writeup on how or why something is the way it is. But with Claude, I would get a much larger, yet still managable explanation of concepts and ideas that I was able to build off of through further chats. And the extended chat history allowed my to easily scroll through my answers, compare results, and pick and choose the best info or code implementation, without having a million tabs of stack overflow open.

Another great experience was learning about all these tools and libraries. It was a great deal of fun exploring the halls of python libraries once more, and it made me enjoy working with the language even more than I already did. I am continually staggered by the amount of opportunities python provides for developers. Even some of the struggles I went through with debugging caused me to learn more about the on the ground workings of server hosting, http and stdio messaging, and json formatting. I had experienced all of this before, but when I use it in a new manner, you are always gonna learn something new.

The last major benefit I saw was with the MCP server itself. It sounds a bit strange, but once I had the server connected to Claude desktop, my mind exploded with ideas of how this could be used. The intuitiveness with which the model was able to use the various MCP tools it had available really made me excited to see where this protocol could go, and how I could develop new features (both wholecloth and upgrades to existing projects).

But that doesn't mean it was all sunshien and rainbows.

## The Detriments I Ran Into
While the speed of code generation helped to accelerate the actually process of writing the code, debugging was a whole separate beast. Decently often, I would have to resort back to sifting through google searches because the model suggested an incorrect debugging method, or simply kept giving the same debugging info that had not worked. I distinctly remember an issue with the python test script, where it was unable to properly use a library to connect to the MCP server to test the tools. After scouring over the code and documentation online, I realized it was because Claude had suggested an incorrect library that was unable to send over the parameters in the correct format, leading to the domino of issues I was running into. I was able to change the library and get it working, but that is time I could have used to expand the tools of the server.

The next issue I ran into was the debugging experience. I know in the benefits section I talked about how much I learned from debugging, but that was from when the debugging had a clear path. Unfortunately, Claude Desktop's debugging capabilities are extremely limited. You only really get a simple error message in the chat window that provides no real detail on what went wrong, and then one log file that again does not provide a ton in terms of information to go off of. I ended up having to do a lot of my debugging using extensive log statements which (while always good) meant that the code became quite bloated with log statements and it felt more unorganized and difficult to read.

Another major issue I ran into was the age of the output from Claude. I don't mean that in the literal sense, but with regard to the data that Claude was trained on. I was using more recent libraries and tools, so even though most of the info I got was good, there was a healthy amount that concerned a version of the library that I was not using. And while this can be excused for something liek a Python library as I could rollback to a previous version, I also saw this when getting the instructions for connecting to Claude Desktop, which I have no way to rollback or modify to match the instructions. I realized pretty quickly that my plan to still use other docs and websites as artifacts of truth was a good one as I was still able to find good info and work around the hallucinations.

The final issue regarded the output when using context to modify files. Don't get me wrong, this does really help with adding functions and individual components, but there were multiple times when I would give Claude context and ask it only to do one specific thing, only to see in the output a random other thing changed. While this did not lead to any issues as I did not let Claude alter my code directly, it meant I had to be quite cautious with implementing the output, as I had to be absolutely sure there were no erroneous changes.

## At the End of the Day
This was a fun project, and I don't mean in the "I was laughing the whole time" way, but in the software engineering way: digging into a new technology, figuring out how it works, the highs of seeing a test pass, the lows of trying to fix a sneaky bug, and the elation of seeing it all come together. It was great to use MCP in a focused and yet still open way. I really felt that I was able to experiment with what I could create, while not being left so open that that freedom became a desert.

If I could turn back time (if I could find a way), there are certainly some things I would change about my approach (mainly with regard to the debugging and the code snippets from Claude) and many things I would like to add (was a bit too late into the project that I had the idea to try and connect to the github api to be able to collect info like commits, branches, etc.), but even still I am proud of what I built and happy that I was able to do it.


 

